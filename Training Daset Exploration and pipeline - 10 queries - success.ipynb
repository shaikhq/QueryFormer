{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9c5213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "037bec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.util import Normalizer\n",
    "from model.database_util import get_hist_file, get_job_table_sample, collator\n",
    "from model.model import QueryFormer\n",
    "from model.database_util import Encoding\n",
    "from model.dataset import PlanTreeDataset\n",
    "from model.trainer import eval_workload, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "822fdcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/imdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fbcd4773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # bs = 1024\n",
    "    # SQ: smaller batch size\n",
    "    bs = 128\n",
    "    lr = 0.001\n",
    "    # epochs = 200\n",
    "    epochs = 45\n",
    "    clip_size = 50\n",
    "    embed_size = 64\n",
    "    pred_hid = 128\n",
    "    ffn_dim = 128\n",
    "    head_size = 12\n",
    "    n_layers = 8\n",
    "    dropout = 0.1\n",
    "    sch_decay = 0.6\n",
    "    # device = 'cuda:0'\n",
    "    device = 'cpu'\n",
    "    newpath = './results/full/cost/'\n",
    "    to_predict = 'cost'\n",
    "args = Args()\n",
    "\n",
    "import os\n",
    "if not os.path.exists(args.newpath):\n",
    "    os.makedirs(args.newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aace65f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:76: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['freq'][i] = freq_np\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n",
      "/Users/shaikhq/coding/QueryFormer/model/database_util.py:89: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  hist_file['bins'][rid] = \\\n"
     ]
    }
   ],
   "source": [
    "hist_file = get_hist_file(data_path + 'histogram_string.csv')\n",
    "cost_norm = Normalizer(-3.61192, 12.290855)\n",
    "card_norm = Normalizer(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e5f421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_ckpt = torch.load('checkpoints/encoding.pt')\n",
    "type(encoding_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "adbb38f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoding'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb839f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.database_util.Encoding"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = encoding_ckpt['encoding']\n",
    "type(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335b172",
   "metadata": {},
   "source": [
    "## Exploring Encoding object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "086ed48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t.id': [1.0, 2528312.0], 't.kind_id': [1.0, 7.0], 't.production_year': [1880.0, 2019.0], 'mc.id': [1.0, 2609129.0], 'mc.company_id': [1.0, 234997.0], 'mc.movie_id': [2.0, 2525745.0], 'mc.company_type_id': [1.0, 2.0], 'ci.id': [1.0, 36244344.0], 'ci.movie_id': [1.0, 2525975.0], 'ci.person_id': [1.0, 4061926.0], 'ci.role_id': [1.0, 11.0], 'mi.id': [1.0, 14835720.0], 'mi.movie_id': [1.0, 2526430.0], 'mi.info_type_id': [1.0, 110.0], 'mi_idx.id': [1.0, 1380035.0], 'mi_idx.movie_id': [2.0, 2525793.0], 'mi_idx.info_type_id': [99.0, 113.0], 'mk.id': [1.0, 4523930.0], 'mk.movie_id': [2.0, 2525971.0], 'mk.keyword_id': [1.0, 134170.0]}\n"
     ]
    }
   ],
   "source": [
    "print(encoding.column_min_max_vals)\n",
    "# column_min_max_vals is a dictionary. It has the min and max value for each numeric column in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d42de580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t.id': 0, 't.kind_id': 1, 't.production_year': 2, 'mc.id': 3, 'mc.company_id': 4, 'mc.movie_id': 5, 'mc.company_type_id': 6, 'ci.id': 7, 'ci.movie_id': 8, 'ci.person_id': 9, 'ci.role_id': 10, 'mi.id': 11, 'mi.movie_id': 12, 'mi.info_type_id': 13, 'mi_idx.id': 14, 'mi_idx.movie_id': 15, 'mi_idx.info_type_id': 16, 'mk.id': 17, 'mk.movie_id': 18, 'mk.keyword_id': 19, 'NA': 20}\n"
     ]
    }
   ],
   "source": [
    "print(encoding.col2idx)\n",
    "# the label encoding of each unique column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8bd229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'>': 0, '=': 1, '<': 2, 'NA': 3}\n"
     ]
    }
   ],
   "source": [
    "print(encoding.op2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5d23a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 't.id', 1: 't.kind_id', 2: 't.production_year', 3: 'mc.id', 4: 'mc.company_id', 5: 'mc.movie_id', 6: 'mc.company_type_id', 7: 'ci.id', 8: 'ci.movie_id', 9: 'ci.person_id', 10: 'ci.role_id', 11: 'mi.id', 12: 'mi.movie_id', 13: 'mi.info_type_id', 14: 'mi_idx.id', 15: 'mi_idx.movie_id', 16: 'mi_idx.info_type_id', 17: 'mk.id', 18: 'mk.movie_id', 19: 'mk.keyword_id', 20: 'NA'}\n"
     ]
    }
   ],
   "source": [
    "print(encoding.idx2col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cec6d6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gather': 0, 'Hash Join': 1, 'Seq Scan': 2, 'Hash': 3, 'Bitmap Heap Scan': 4, 'Bitmap Index Scan': 5, 'Nested Loop': 6, 'Index Scan': 7, 'Merge Join': 8, 'Gather Merge': 9, 'Materialize': 10, 'BitmapAnd': 11, 'Sort': 12}\n"
     ]
    }
   ],
   "source": [
    "print(encoding.type2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b660cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoints/cost_model.pt', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71759b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.util import seed_everything\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9592f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QueryFormer(emb_size = args.embed_size ,ffn_dim = args.ffn_dim, head_size = args.head_size, \\\n",
    "                 dropout = args.dropout, n_layers = args.n_layers, \\\n",
    "                 use_sample = True, use_hist = True, \\\n",
    "                 pred_hid = args.pred_hid\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "85e27584",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c8a7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = 'cost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4286ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_path = './data/imdb/'\n",
    "dfs = []  # list to hold DataFrames\n",
    "# SQ: added\n",
    "for i in range(2):\n",
    "#for i in range(18):\n",
    "    file = imdb_path + 'plan_and_cost/train_plan_part{}.csv'.format(i)\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "full_train_df = pd.concat(dfs)\n",
    "\n",
    "val_dfs = []  # list to hold DataFrames\n",
    "for i in range(18,20):\n",
    "    file = imdb_path + 'plan_and_cost/train_plan_part{}.csv'.format(i)\n",
    "    df = pd.read_csv(file)\n",
    "    val_dfs.append(df)\n",
    "\n",
    "val_df = pd.concat(val_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dd8301be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded queries with len  100000\n",
      "Loaded bitmaps\n"
     ]
    }
   ],
   "source": [
    "table_sample = get_job_table_sample(imdb_path+'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06ae89",
   "metadata": {},
   "source": [
    "## Exploring Histogram input (hist_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f377f08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hist_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f4119781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>column</th>\n",
       "      <th>freq</th>\n",
       "      <th>bins</th>\n",
       "      <th>table_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>production_year</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1880, 1913, 1923, 1942, 1955, 1960, 1964, 196...</td>\n",
       "      <td>t.production_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title</td>\n",
       "      <td>kind_id</td>\n",
       "      <td>[0.0, 0.26216118191156074, 0.03593387047716835...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, ...</td>\n",
       "      <td>t.kind_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie_companies</td>\n",
       "      <td>company_id</td>\n",
       "      <td>[0.0, 0.0004959511376981121, 0.000558807386989...</td>\n",
       "      <td>[1, 6, 19, 27, 68, 133, 160, 189, 292, 402, 47...</td>\n",
       "      <td>mc.company_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie_companies</td>\n",
       "      <td>company_type_id</td>\n",
       "      <td>[0.0, 0.4883796425472418, 0.5116203574527581]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>mc.company_type_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cast_info</td>\n",
       "      <td>role_id</td>\n",
       "      <td>[0.0, 0.3495907485479872, 0.20560375449487386,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>ci.role_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             table           column  \\\n",
       "0            title  production_year   \n",
       "1            title          kind_id   \n",
       "2  movie_companies       company_id   \n",
       "3  movie_companies  company_type_id   \n",
       "4        cast_info          role_id   \n",
       "\n",
       "                                                freq  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.26216118191156074, 0.03593387047716835...   \n",
       "2  [0.0, 0.0004959511376981121, 0.000558807386989...   \n",
       "3      [0.0, 0.4883796425472418, 0.5116203574527581]   \n",
       "4  [0.0, 0.3495907485479872, 0.20560375449487386,...   \n",
       "\n",
       "                                                bins        table_column  \n",
       "0  [1880, 1913, 1923, 1942, 1955, 1960, 1964, 196...   t.production_year  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, ...           t.kind_id  \n",
       "2  [1, 6, 19, 27, 68, 133, 160, 189, 292, 402, 47...       mc.company_id  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  mc.company_type_id  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          ci.role_id  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e108ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 5)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f590fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>column</th>\n",
       "      <th>freq</th>\n",
       "      <th>bins</th>\n",
       "      <th>table_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>production_year</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1880, 1913, 1923, 1942, 1955, 1960, 1964, 196...</td>\n",
       "      <td>t.production_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title</td>\n",
       "      <td>kind_id</td>\n",
       "      <td>[0.0, 0.26216118191156074, 0.03593387047716835...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, ...</td>\n",
       "      <td>t.kind_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie_companies</td>\n",
       "      <td>company_id</td>\n",
       "      <td>[0.0, 0.0004959511376981121, 0.000558807386989...</td>\n",
       "      <td>[1, 6, 19, 27, 68, 133, 160, 189, 292, 402, 47...</td>\n",
       "      <td>mc.company_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie_companies</td>\n",
       "      <td>company_type_id</td>\n",
       "      <td>[0.0, 0.4883796425472418, 0.5116203574527581]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>mc.company_type_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cast_info</td>\n",
       "      <td>role_id</td>\n",
       "      <td>[0.0, 0.3495907485479872, 0.20560375449487386,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>ci.role_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>movie_keyword</td>\n",
       "      <td>keyword_id</td>\n",
       "      <td>[0.0, 0.0031748950967179193, 1.989421142551088...</td>\n",
       "      <td>[1, 77, 132, 230, 331, 347, 384, 495, 643, 784...</td>\n",
       "      <td>mk.keyword_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cast_info</td>\n",
       "      <td>person_id</td>\n",
       "      <td>[0.0, 0.0, 5.518102507748589e-08, 2.7590512538...</td>\n",
       "      <td>[2, 77446, 145798, 212750, 281691, 347240, 419...</td>\n",
       "      <td>ci.person_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>movie_info_idx</td>\n",
       "      <td>info_type_id</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 9...</td>\n",
       "      <td>mi_idx.info_type_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movie_info</td>\n",
       "      <td>info_type_id</td>\n",
       "      <td>[0.0, 0.05406815807174563, 0.08688004942665738...</td>\n",
       "      <td>[1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, ...</td>\n",
       "      <td>mi.info_type_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             table           column  \\\n",
       "0            title  production_year   \n",
       "1            title          kind_id   \n",
       "2  movie_companies       company_id   \n",
       "3  movie_companies  company_type_id   \n",
       "4        cast_info          role_id   \n",
       "5    movie_keyword       keyword_id   \n",
       "6        cast_info        person_id   \n",
       "7   movie_info_idx     info_type_id   \n",
       "8       movie_info     info_type_id   \n",
       "\n",
       "                                                freq  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.26216118191156074, 0.03593387047716835...   \n",
       "2  [0.0, 0.0004959511376981121, 0.000558807386989...   \n",
       "3      [0.0, 0.4883796425472418, 0.5116203574527581]   \n",
       "4  [0.0, 0.3495907485479872, 0.20560375449487386,...   \n",
       "5  [0.0, 0.0031748950967179193, 1.989421142551088...   \n",
       "6  [0.0, 0.0, 5.518102507748589e-08, 2.7590512538...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.05406815807174563, 0.08688004942665738...   \n",
       "\n",
       "                                                bins         table_column  \n",
       "0  [1880, 1913, 1923, 1942, 1955, 1960, 1964, 196...    t.production_year  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, ...            t.kind_id  \n",
       "2  [1, 6, 19, 27, 68, 133, 160, 189, 292, 402, 47...        mc.company_id  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   mc.company_type_id  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           ci.role_id  \n",
       "5  [1, 77, 132, 230, 331, 347, 384, 495, 643, 784...        mk.keyword_id  \n",
       "6  [2, 77446, 145798, 212750, 281691, 347240, 419...         ci.person_id  \n",
       "7  [99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 9...  mi_idx.info_type_id  \n",
       "8  [1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, ...      mi.info_type_id  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_file.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf8a50c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "table           object\n",
       "column          object\n",
       "freq            object\n",
       "bins            object\n",
       "table_column    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_file.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "567edfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: table\n",
      "table\n",
      "<class 'str'>    9\n",
      "Name: count, dtype: int64\n",
      "Sample Value: title\n",
      "\n",
      "\n",
      "Column: column\n",
      "column\n",
      "<class 'str'>    9\n",
      "Name: count, dtype: int64\n",
      "Sample Value: production_year\n",
      "\n",
      "\n",
      "Column: freq\n",
      "freq\n",
      "<class 'numpy.ndarray'>    9\n",
      "Name: count, dtype: int64\n",
      "Sample Value: [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.22139046e-06\n",
      " 0.00000000e+00 8.14260304e-07]\n",
      "Length of Sample Value: 2020\n",
      "\n",
      "\n",
      "Column: bins\n",
      "bins\n",
      "<class 'list'>    9\n",
      "Name: count, dtype: int64\n",
      "Sample Value: [1880, 1913, 1923, 1942, 1955, 1960, 1964, 1968, 1971, 1975, 1978, 1982, 1985, 1987, 1990, 1992, 1994, 1995, 1996, 1998, 1999, 2000, 2001, 2001, 2002, 2003, 2004, 2004, 2005, 2005, 2006, 2006, 2007, 2007, 2007, 2008, 2008, 2009, 2009, 2009, 2010, 2010, 2010, 2011, 2011, 2011, 2012, 2012, 2012, 2013, 2019]\n",
      "Length of Sample Value: 51\n",
      "\n",
      "\n",
      "Column: table_column\n",
      "table_column\n",
      "<class 'str'>    9\n",
      "Name: count, dtype: int64\n",
      "Sample Value: t.production_year\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in ['table', 'column', 'freq', 'bins', 'table_column']:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(hist_file[column].apply(type).value_counts())\n",
    "    sample_value = hist_file[column].iloc[0]\n",
    "    print(f\"Sample Value: {sample_value}\")\n",
    "    if isinstance(sample_value, (list, tuple, set, dict, pd.Series, np.ndarray)):\n",
    "        print(f\"Length of Sample Value: {len(sample_value)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257143c",
   "metadata": {},
   "source": [
    "# Step 1: Identifying the training dataset and its component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "98d193b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PlanTreeDataset(full_train_df, None, encoding, hist_file, card_norm, cost_norm, to_predict, table_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eb32ba",
   "metadata": {},
   "source": [
    "# Step 2: Exploring full_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "506ced46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(full_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7c0c0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17ae5bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{\"Plan\": {\"Node Type\": \"Gather\", \"Parallel Awa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{\"Plan\": {\"Node Type\": \"Seq Scan\", \"Parallel A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               json\n",
       "0   0  {\"Plan\": {\"Node Type\": \"Gather\", \"Parallel Awa...\n",
       "1   1  {\"Plan\": {\"Node Type\": \"Seq Scan\", \"Parallel A..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc0ead2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       int64\n",
       "json    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2c2b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Plan\": {\"Node Type\": \"Gather\", \"Parallel Aware\": false, \"Startup Cost\": 23540.58, \"Total Cost\": 154548.95, \"Plan Rows\": 567655, \"Plan Width\": 119, \"Actual Startup Time\": 386.847, \"Actual Total Time\": 646.972, \"Actual Rows\": 283812, \"Actual Loops\": 1, \"Workers Planned\": 2, \"Workers Launched\": 2, \"Single Copy\": false, \"Plans\": [{\"Node Type\": \"Hash Join\", \"Parent Relationship\": \"Outer\", \"Parallel Aware\": true, \"Join Type\": \"Inner\", \"Startup Cost\": 22540.58, \"Total Cost\": 96783.45, \"Plan Rows\": 236523, \"Plan Width\": 119, \"Actual Startup Time\": 369.985, \"Actual Total Time\": 518.487, \"Actual Rows\": 94604, \"Actual Loops\": 3, \"Inner Unique\": false, \"Hash Cond\": \"(t.id = mi_idx.movie_id)\", \"Workers\": [], \"Plans\": [{\"Node Type\": \"Seq Scan\", \"Parent Relationship\": \"Outer\", \"Parallel Aware\": true, \"Relation Name\": \"title\", \"Alias\": \"t\", \"Startup Cost\": 0.0, \"Total Cost\": 49166.46, \"Plan Rows\": 649574, \"Plan Width\": 94, \"Actual Startup Time\": 0.366, \"Actual Total Time\": 147.047, \"Actual Rows\": 514421, \"Actual Loops\": 3, \"Filter\": \"(kind_id = 7)\", \"Rows Removed by Filter\": 328349, \"Workers\": []}, {\"Node Type\": \"Hash\", \"Parent Relationship\": \"Inner\", \"Parallel Aware\": true, \"Startup Cost\": 15122.68, \"Total Cost\": 15122.68, \"Plan Rows\": 383592, \"Plan Width\": 25, \"Actual Startup Time\": 103.547, \"Actual Total Time\": 103.547, \"Actual Rows\": 306703, \"Actual Loops\": 3, \"Hash Buckets\": 65536, \"Original Hash Buckets\": 65536, \"Hash Batches\": 32, \"Original Hash Batches\": 32, \"Peak Memory Usage\": 1920, \"Workers\": [], \"Plans\": [{\"Node Type\": \"Seq Scan\", \"Parent Relationship\": \"Outer\", \"Parallel Aware\": true, \"Relation Name\": \"movie_info_idx\", \"Alias\": \"mi_idx\", \"Startup Cost\": 0.0, \"Total Cost\": 15122.68, \"Plan Rows\": 383592, \"Plan Width\": 25, \"Actual Startup Time\": 0.28, \"Actual Total Time\": 54.382, \"Actual Rows\": 306703, \"Actual Loops\": 3, \"Filter\": \"(info_type_id > 99)\", \"Rows Removed by Filter\": 153308, \"Workers\": []}]}]}]}, \"Planning Time\": 2.382, \"Triggers\": [], \"Execution Time\": 654.241}\n"
     ]
    }
   ],
   "source": [
    "# printing a sample json string in full\n",
    "json_sample = full_train_df['json'].iloc[0]\n",
    "print(json_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0d31b0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Plan\": {\n",
      "        \"Node Type\": \"Gather\",\n",
      "        \"Parallel Aware\": false,\n",
      "        \"Startup Cost\": 23540.58,\n",
      "        \"Total Cost\": 154548.95,\n",
      "        \"Plan Rows\": 567655,\n",
      "        \"Plan Width\": 119,\n",
      "        \"Actual Startup Time\": 386.847,\n",
      "        \"Actual Total Time\": 646.972,\n",
      "        \"Actual Rows\": 283812,\n",
      "        \"Actual Loops\": 1,\n",
      "        \"Workers Planned\": 2,\n",
      "        \"Workers Launched\": 2,\n",
      "        \"Single Copy\": false,\n",
      "        \"Plans\": [\n",
      "            {\n",
      "                \"Node Type\": \"Hash Join\",\n",
      "                \"Parent Relationship\": \"Outer\",\n",
      "                \"Parallel Aware\": true,\n",
      "                \"Join Type\": \"Inner\",\n",
      "                \"Startup Cost\": 22540.58,\n",
      "                \"Total Cost\": 96783.45,\n",
      "                \"Plan Rows\": 236523,\n",
      "                \"Plan Width\": 119,\n",
      "                \"Actual Startup Time\": 369.985,\n",
      "                \"Actual Total Time\": 518.487,\n",
      "                \"Actual Rows\": 94604,\n",
      "                \"Actual Loops\": 3,\n",
      "                \"Inner Unique\": false,\n",
      "                \"Hash Cond\": \"(t.id = mi_idx.movie_id)\",\n",
      "                \"Workers\": [],\n",
      "                \"Plans\": [\n",
      "                    {\n",
      "                        \"Node Type\": \"Seq Scan\",\n",
      "                        \"Parent Relationship\": \"Outer\",\n",
      "                        \"Parallel Aware\": true,\n",
      "                        \"Relation Name\": \"title\",\n",
      "                        \"Alias\": \"t\",\n",
      "                        \"Startup Cost\": 0.0,\n",
      "                        \"Total Cost\": 49166.46,\n",
      "                        \"Plan Rows\": 649574,\n",
      "                        \"Plan Width\": 94,\n",
      "                        \"Actual Startup Time\": 0.366,\n",
      "                        \"Actual Total Time\": 147.047,\n",
      "                        \"Actual Rows\": 514421,\n",
      "                        \"Actual Loops\": 3,\n",
      "                        \"Filter\": \"(kind_id = 7)\",\n",
      "                        \"Rows Removed by Filter\": 328349,\n",
      "                        \"Workers\": []\n",
      "                    },\n",
      "                    {\n",
      "                        \"Node Type\": \"Hash\",\n",
      "                        \"Parent Relationship\": \"Inner\",\n",
      "                        \"Parallel Aware\": true,\n",
      "                        \"Startup Cost\": 15122.68,\n",
      "                        \"Total Cost\": 15122.68,\n",
      "                        \"Plan Rows\": 383592,\n",
      "                        \"Plan Width\": 25,\n",
      "                        \"Actual Startup Time\": 103.547,\n",
      "                        \"Actual Total Time\": 103.547,\n",
      "                        \"Actual Rows\": 306703,\n",
      "                        \"Actual Loops\": 3,\n",
      "                        \"Hash Buckets\": 65536,\n",
      "                        \"Original Hash Buckets\": 65536,\n",
      "                        \"Hash Batches\": 32,\n",
      "                        \"Original Hash Batches\": 32,\n",
      "                        \"Peak Memory Usage\": 1920,\n",
      "                        \"Workers\": [],\n",
      "                        \"Plans\": [\n",
      "                            {\n",
      "                                \"Node Type\": \"Seq Scan\",\n",
      "                                \"Parent Relationship\": \"Outer\",\n",
      "                                \"Parallel Aware\": true,\n",
      "                                \"Relation Name\": \"movie_info_idx\",\n",
      "                                \"Alias\": \"mi_idx\",\n",
      "                                \"Startup Cost\": 0.0,\n",
      "                                \"Total Cost\": 15122.68,\n",
      "                                \"Plan Rows\": 383592,\n",
      "                                \"Plan Width\": 25,\n",
      "                                \"Actual Startup Time\": 0.28,\n",
      "                                \"Actual Total Time\": 54.382,\n",
      "                                \"Actual Rows\": 306703,\n",
      "                                \"Actual Loops\": 3,\n",
      "                                \"Filter\": \"(info_type_id > 99)\",\n",
      "                                \"Rows Removed by Filter\": 153308,\n",
      "                                \"Workers\": []\n",
      "                            }\n",
      "                        ]\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"Planning Time\": 2.382,\n",
      "    \"Triggers\": [],\n",
      "    \"Execution Time\": 654.241\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# pretty print the json object\n",
    "import json\n",
    "# the following code parses the json string into a dictionary\n",
    "json_parsed = json.loads(json_sample)\n",
    "json_pretty = json.dumps(json_parsed, indent=4)\n",
    "print(json_pretty)\n",
    "\n",
    "with open('output.json', 'w') as f:\n",
    "    f.write(json_pretty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1148484f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.database_util.Encoding"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0dba5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = PlanTreeDataset(val_df, None, encoding, hist_file, card_norm, cost_norm, to_predict, table_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bdcefceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Avg Loss: 0.00015329097853973507, Time: 41.42007398605347\n",
      "Median: 2.928444377690787\n",
      "Mean: 449.13245681912656\n",
      "Epoch: 20  Avg Loss: 9.051527210976929e-06, Time: 890.048810005188\n",
      "Median: 1.190994000093597\n",
      "Mean: 1.6319231603649687\n",
      "Epoch: 40  Avg Loss: 7.69963618076872e-06, Time: 1726.8186321258545\n",
      "Median: 1.1766559018761633\n",
      "Mean: 1.5472035230118144\n"
     ]
    }
   ],
   "source": [
    "crit = nn.MSELoss()\n",
    "model, best_path = train(model, train_ds, val_ds, crit, cost_norm, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc344e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1095a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bfa517f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    'get_sample' : get_job_table_sample,\n",
    "    'encoding': encoding,\n",
    "    'cost_norm': cost_norm,\n",
    "    'hist_file': hist_file,\n",
    "    'model': model,\n",
    "    'device': args.device,\n",
    "    'bs': 512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b14a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e7796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fd89df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded queries with len  70\n",
      "Loaded bitmaps\n",
      "Median: 1.6471430303309913\n",
      "Mean: 19.293510404012288\n",
      "Corr:  0.8708629547656623\n"
     ]
    }
   ],
   "source": [
    "_ = eval_workload('job-light', methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9e40c30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded queries with len  5000\n",
      "Loaded bitmaps\n",
      "Median: 1.1351381926301887\n",
      "Mean: 1.6124878862677317\n",
      "Corr:  0.9828999983362362\n"
     ]
    }
   ],
   "source": [
    "_ = eval_workload('synthetic', methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30aceed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47dfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0622ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b92aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ceb39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
